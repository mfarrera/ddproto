\section{Execution Engine Requirements}

NOTE: This document is a work in progress and this section should be taken as my opinion on what we could use as a criteria to compare runtimes.
This list has not been agreed and it needs more work.

\subsection{The data flow environment}

The structure of data: Introduce terminology and assumptions about how the program should work, a binary will be generated ...

\subsection{Requirements}

After analysing the SDP challenge we have defined the following list of requirements/challenges that will guide our comparison of existing execution engines:
\begin{itemize}
\item Data Layout. The programming model should provide a way to layout data that supports partitions for handling irregularly sampled collections.
Our visibility data requires more computation for higher frequency band so we would like to distribute data in a way that where high frequency band
visibilities are together the data chunk is smaller and for low frequencies the chunks are bigger to distribute computation evenly across the machine.
\item Memory management: Another challenge related to data occurs when the amount of data needed by a task exceeds the physical available memory. 
The programming model should provide a way to handle this situation (i.e. using files or mapping memory on demand ...) as transparent to the programmer as possible. Also related with memory management there will be the situation when the memory requirements of two tasks exceeds the amount of available physical memory, in that case runtime should take the memory demands into account during task scheduling so that tasks do not run together and prevent swapping.  
\item Scalability: we seek to achieve scalability up to 8K nodes.
\item Interoperability: Tasks may be written in  MPI, CUDA, Python?, OpenMP, OpenACC and Interface with convenient foreign functions  (i.e fft library)
\item I/O: a way to get data into the system (visibility data comes from the TM, streaming, and then from buffer, other data i.e. sky model, telescope state is in the storage service (file?)
\item performance: the overhead added by the runtime should be acceptable, performance comparable to an MPI program (ASKAPSoft). There is a timeout: the program should run before the next observation is available (6 hours). Factors that affect the overhead of a runtime are: communication overhead (we can measure latency and bandwidth between two nodes and bi-sectional bandwidth using the full 8k nodes), runtime overhead (when communication is not an issue, we would like to measure performance of an embarassingly parallel program which should be comparable to SPMD program (i.e. MPI). Data transposition: A two-dimensional region will be used row-wise by a certain number of tasks but it will need to be used colum-wise by a different tasks, so, effectively it will require a transposition of the data, we would like to measure how the runtime can handle this (without explicitely using collective operations) 
\item resilience: the runtime must be stable enough to handle hardware failures, and take into account hints from the "driven program" which will tell the system the liveness of its k-inputs and output data (preciousness) and upon a failure of up to $m$ of the $k$ inputs compute a partial answer without an error condition.
\item Maintainability/ Extensibility: tasks and runtime should be separated by a well defined interface so that functionality can be extended with very little knowledge 
\item Performance Portability/ Extensibility: the runtime should be portable to different platforms and specifically should be able to run in a upgraded hardware (i.e with added memory per node, better network, more nodes ...) and take advantadge of the new available resources with minimal changes to the code.
\end{itemize}

Input Data : ~1000 FLOPs/byte read from storage
Need to be able to use accelerators
Working memory in GigaBytes/task â€“ limits usable parallelism
Very high degree of intrinsic parallelism for most analysis stages
Data I/O and communications in large (Megabyte + ) blocks
Intrinsic processing stages are short(ish): ~0.01s duration and ~100 FLOPs/byte of input/output
Minimum scalability to ~10000 nodes
Iterative (but few) and data-dependent (but at few points) algorithms
Some processing stages require bringing together large fraction of intermediate data products

\subsection{micro-benchmarks}

\subsection{Candidate systems}
We have identified two groups of systems that could potentially be suitable for SDP. 
\begin{itemize}
\item HPC task oriented programing models. These models emerged as a response to a demand for productivity in parallel programing for HPC.
The Message Passing Interface(MPI)\footnote{http://www.mpi-forum.org} is the de-facto standard to program distributed memory systems, while good 
performance can be achieved it requires low level tunnig and productivity and maintainability are low. For shared memory systems
OpenMP\footnote{http://openmp.org} has been very successful offering better productivity for shared memory systems. The research community 
has come up with a number of effors to make this systems more productive while maintainng focus on performance merging the best of both programing models. 
PGAS languages is one of these effords (UPC, X10, Titanium, Chapel ...). Another effort goes iin the direction of task oriented programming 
models. These models we will study in more detail: 
\begin{enumerate}
\item Swift-T 
\item Regent\footnote{http://regent-lang.org/}/Legion\footnote{http://legion.stanford.edu/}
\item Parsec/Drague
\item COMPSS/OMPSS
\item StarPU\footnote{http://starpu.gforge.inria.fr/}
\end{enumerate}
\item Big Data data driven progrmming models. These models targe large-scale data-intensive applications on commodity clusters. 
They follow a model of cluster computing in which data-parallel computations are
executed on clusters of unreliable machines by systems that automatically provide locality-aware scheduling, fault tolerance and load balancing. 
Their primary goal is productivity and they have become very popular as they works well for a number of applications. 
These systems provide a programming model where the user create acyclic data flow graphs to pass input data through a set of operators. 
MapRecude~\cite{mapReduce} pioneered this model, which has been extended (i.e. systems like Dryad~\cite{Dryad} and Map-ReduceMerge~\cite{mapReduceMerge}) to generalize the types of data flows supported, or to target applications that cannot be expressed eficiently as acyclic data flows (i.e Spark targets iterative jobs and interactive analytics).
The following models will be studied in more detail:
\begin{enumerate}
\item Apache Spark\footnote{http://spark.apache.org/}
\item Apache Flink
\item Heron/kafka
\end{enumerate}

\end{itemize}

These two worlds are intersecting, dispite they come from different backgrounds, and we would like to investigate further their features, their performance and
productivity.


NOTE: Temanejo- visual debugging for task-parallelism (supports openMP, OmpSs, SMPSs, StarPU and Parsec. \footnote{http://www.hlrs.de/en/solutions-services/service-portfolio/programming/hpc-development-tools/temanejo/}
StarPU integrates with SImGRID, ompSS with tasksim


